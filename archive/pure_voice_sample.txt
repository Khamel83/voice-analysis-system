Okay, I don't really quite understand everything. The reason I listen to the podcast is it's an old coworker of mine, and so are our logs. Do we need to have all these different logs? Is that the right way to do this? If so, can all of this go somewhere like I want to be able to read a single file and then sort of figure this out. Is this all updated in that evils.md file? I just want to be able to sort of come back to this later.

Okay, well let's update our documentation, push this to GitHub, and then we can call it a day.

Yeah, I mean, it's not even asking you to propose axial codes. I just want to make sure we actually have a log file. Is there a log file that's just logging everything that we're doing that we can use to look at? Or do we not actually have that? We don't have a CSV, like none of this is actually created, this is just an idea. I just want to make sure we actually have the information required to even do this.

From just testing to everything, 55% success rate is still a lot lower than I was expecting, but you know it's better than zero. So for everything in the queue that is not already identified, can we put it through this process? What is it going to take for me to actually trust you that this is happening?

I really need to figure out how do we resolve this schema context issue? The 1-second difference is not a big deal, the smaller footprint is not a big deal, but why would I not want SQL cleaner SQL style? Is it just style or actual results? I don't particularly care about Google vs Meta or anything like that. These are open-source models, so what I'm really trying to figure out is what's the best one that I should be using. I don't know if I have enough from your guide; it seems like LLAMA 3.2 3B is just the best one, and I don't know why I would test GEMMA 2 if I already tested GEMMA 3. So, what do we need to do to fix this schema issue? Because I want it to be a big constraint, and if it needs to be manual that's fine, but what do we need to do?

And also, I might have missed it, but are we saying we don't need to switch to Gemma, or did that get lost in translation? I still want to do the comparison between Gemma and LLaMA.

And again, the fact that sometimes it produces inaccurate sequel is sort of the whole reason I keep asking about you know how messy how precise should we use another model. Again I'm not saying we need to I just want to make sure that we have really clear schema and design so that this doesn't keep happening.

OK, so um it'll be yeah I'm not going to delete the file I'm just saying from my machine, like I don't think we're going back to these files once they're in the usc_hr_analytics.db file, we're not going back to those files, so they can sort of live on the server or something. I don't need to have them taking up space on my machine. All I would need is one-time setup to get all the historical stuff, and then ongoing, I added, but that's it, right? Um, and then I should be able to use the web interface to query the database, and theoretically, I could just give this database to another person on my team, or give this entire project along with the database to another person on my team, one of the analysts, and they could do this as well. I want to prove that this works; I'm not looking to fire anybody; I just kind of want to see if there's a way that we can do our job better. Even if I don't tell anybody about it, that's fine, but I want to sort of understand what the constraints, limits, so on and so forth are, and use the right database, the right models for what we're doing.